{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import genfromtxt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SOM(object):\n",
    "    def __init__(self, m, n):\n",
    "        self.net_dim = np.array([m, n])\n",
    "        self.weights = None\n",
    "        self.hit_map = np.zeros([self.net_dim[0], self.net_dim[1]])\n",
    "        self.init_radius = np.max(self.net_dim)/2\n",
    "        self.umatrix = np.zeros([self.net_dim[0], self.net_dim[1]])\n",
    "        self.umat_2 = np.zeros([self.net_dim[0]*2 - 1, self.net_dim[1]*2 - 1])\n",
    "        self.bmu_list = None\n",
    "        self.label_map = np.zeros([self.net_dim[0], self.net_dim[1]]) + -1\n",
    "        self.classif_log=None # matrix for storing data for each neu, #times it becomed BMU for each class\n",
    "        self.neu_class=np.zeros([m*n])# store class for each neuron \n",
    "        self.trainAccuracy=None\n",
    "        self.testAccuracy=None\n",
    "\n",
    "    def fit_model(self, train_x, train_y=None, init_lr=0.1, epochs=100):\n",
    "        # Initializing the weight matrix\n",
    "        self.weights = np.random.random((self.net_dim[0], self.net_dim[1], train_x.shape[1]))\n",
    "        self.bmu_list = np.zeros(train_x.shape[0])\n",
    "        time_constant = epochs/np.log(self.init_radius)\n",
    "        \n",
    "        if not (train_y is None):\n",
    "            #print(\"np.unique(train_y).shape[0]\",np.unique(train_y).shape[0])\n",
    "            self.classif_log=np.zeros([np.unique(train_y).shape[0] , self.net_dim[0]*self.net_dim[1]])\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print('Processing epoch:{}'.format(epoch))\n",
    "            \"\"\"decay the radius and the learning rate\"\"\"\n",
    "            if epoch != 0:\n",
    "                radius = SOM.decay_radius(self.init_radius,epoch, time_constant)\n",
    "                lr = SOM.decay_learning_rate(init_lr, epoch, epochs)\n",
    "\n",
    "            else:\n",
    "                radius = self.init_radius\n",
    "                lr = init_lr\n",
    "\n",
    "            #print(\"train_x.shape[0]\",train_x.shape[0])            \n",
    "            randlist=random.sample(range(train_x.shape[0]), train_x.shape[0])\n",
    "            for t in range(train_x.shape[0]):\n",
    "\n",
    "                # Picking a random pattern\n",
    "                r = randlist[t]                \n",
    "                # Finding the bmu for the random pattern\n",
    "                bmu_index, bmu = self.find_bmu(train_x[r, :])\n",
    "                #print(\"bmu_index : \",bmu_index) \n",
    "                self.bmu_list[r] = bmu_index[0]*self.weights.shape[1] + bmu_index[1]\n",
    "                #print(\"self.bmu_list[r] :: \",self.bmu_list[r])\n",
    "\n",
    "                # updating the weights\n",
    "                for i in range(self.net_dim[0]):\n",
    "                    for j in range(self.net_dim[1]):\n",
    "                        w = self.weights[i, j, :]\n",
    "                        w_bmu_dist = SOM.get_distance(w, bmu)\n",
    "\n",
    "                        h = self.get_gaussian_membership(w_bmu_dist, radius)\n",
    "                        delta_w = (lr * h * (train_x[r, :] - w))\n",
    "                        new_w = w + delta_w\n",
    "                        self.weights[i, j, :] = new_w                        \n",
    "                        if np.isnan(self.weights).any():\n",
    "                            print(' weights NaN at epoch {}'.format(epoch))\n",
    "\n",
    "                            return\n",
    "                        # print('\\n')\n",
    "            ##\n",
    "            if not (train_y is None) :       \n",
    "                for t in range(train_x.shape[0]):\n",
    "                    bmu_index, bmu = self.find_bmu(train_x[t, :])\n",
    "                    self.bmu_list[t] = bmu_index[0]*self.weights.shape[1] + bmu_index[1]\n",
    "                    #print(\"self.bmu_list[r]\",self.bmu_list[r])\n",
    "                    self.classif_log[int(train_y[t]),int(self.bmu_list[t])]=(self.classif_log[int(train_y[t]),int(self.bmu_list[t])])+1\n",
    "                print(\"Train Accuracy\",(sum(self.classif_log.max(axis=0))*100)/ (train_x.shape[0]) )\n",
    "                self.classif_log=np.zeros([np.unique(train_y).shape[0] , self.net_dim[0]*self.net_dim[1]])\n",
    "                self.trainAccuracy=(sum(self.classif_log.max(axis=0))*100)/ (train_x.shape[0])\n",
    " \n",
    "        if not (train_y is None) :       \n",
    "            for t in range(train_x.shape[0]):\n",
    "                bmu_index, bmu = self.find_bmu(train_x[t, :])\n",
    "                self.bmu_list[t] = bmu_index[0]*self.weights.shape[1] + bmu_index[1]\n",
    "                #print(\"self.bmu_list[r]\",self.bmu_list[r])\n",
    "                \"\"\"                    \n",
    "                print(\"bla\", bmu_index,bmu ,\" t\",t) # bla [0, 2] [-0.002496    0.00031421 -0.00322767] print(\"Train y val :\",int(train_y[t]))\n",
    "                print(\"self.bmu_list :\",int(self.bmu_list[t]))\n",
    "                \"\"\"\n",
    "                #print(\"int(train_y[t])\",int(train_y[t]) )\n",
    "                #print(\"int(self.bmu_list[t])\",int(self.bmu_list[t]))\n",
    "                self.classif_log[int(train_y[t]),int(self.bmu_list[t])]=(self.classif_log[int(train_y[t]),int(self.bmu_list[t])])+1\n",
    "                        \n",
    "            print(\"Check \\n\",self.classif_log)        \n",
    "            self.neu_class=self.classif_log.argmax(axis=0) \n",
    "            print(\"self.neu_class\",self.neu_class)\n",
    "            print(\"Train Accuracy\",(sum(self.classif_log.max(axis=0))*100)/ (train_x.shape[0]) )\n",
    "            self.trainAccuracy=(sum(self.classif_log.max(axis=0))*100)/ (train_x.shape[0])\n",
    "        self.set_umatrix()\n",
    "        self.set_hitmap()\n",
    "        #now test for accuracy\n",
    "        #if train_y is not None:\n",
    "            #self.set_label_map(train_y)#this needs checking cz it prints something \n",
    "        \n",
    "    def test_model(self, test_x, test_y=None):\n",
    "        \n",
    "        correct=0;\n",
    "        \n",
    "        for t in range(test_x.shape[0]):\n",
    "            bmu_index, bmu = self.find_bmu(test_x[t, :])\n",
    "            neu_no=bmu_index[0]*self.weights.shape[1] + bmu_index[1]\n",
    "            #print(\"neu_no : \",neu_no)\n",
    "            class_label=self.neu_class[neu_no]\n",
    "\n",
    "            if(class_label==test_y[t]):\n",
    "                correct=correct+1\n",
    "        print(\"Test Accuracy : \", (correct*100/test_x.shape[0]))\n",
    "        self.testAccuracy=(correct*100/test_x.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "    def find_bmu(self, x):\n",
    "        min_dist = float('inf')\n",
    "        bmu_index = [-1, -1]\n",
    "        bmu = self.weights[0, 0, :]\n",
    "        for i in range(self.net_dim[0]):\n",
    "            for j in range(self.net_dim[1]):\n",
    "                w = self.weights[i, j, :]\n",
    "                d = SOM.get_distance(x, w)\n",
    "                #print(\"d : \",d)\n",
    "                if d < min_dist:\n",
    "                    min_dist = d\n",
    "                    bmu_index = [i, j]\n",
    "                    bmu = w\n",
    "\n",
    "        return bmu_index, bmu\n",
    "    \n",
    "    def find_bmu_list(self, x):\n",
    "        min_dist = float('inf')\n",
    "        bmu_index = [-1, -1]\n",
    "        bmu = self.weights[0, 0, :]\n",
    "        dis_list=[]\n",
    "        for i in range(self.net_dim[0]):\n",
    "            for j in range(self.net_dim[1]):\n",
    "                w = self.weights[i, j, :]\n",
    "                d = SOM.get_distance(x, w)\n",
    "                dis_list.append(d)\n",
    "                #print(\"d : \",d)\n",
    "                if d < min_dist:\n",
    "                    min_dist = d\n",
    "                    bmu_index = [i, j]\n",
    "                    bmu = w\n",
    "        s = dis_list\n",
    "        sorted_list=sorted(range(len(s)), key=lambda k: s[k])\n",
    "        #print(dis_list)\n",
    "        #print(bmu_index)\n",
    "        #print(dis_list[sorted_list[0]])\n",
    "        #print(min_dist)\n",
    "        return bmu_index, bmu, sorted_list\n",
    "\n",
    "    def get_gaussian_membership(self, squared_distance_from_bmu, radius):\n",
    "        h = np.exp(-squared_distance_from_bmu/(2*(radius**2)))\n",
    "        # h = np.exp(squared_distance_from_bmu/(2*(radius**2)))\n",
    "        # print('h:{}'.format(h))\n",
    "        return h\n",
    "\n",
    "    def set_hitmap(self):\n",
    "        unique, counts = np.unique(self.bmu_list, return_counts=True)\n",
    "        #print(\"unique\",unique)\n",
    "        #print(\"counts\",counts)\n",
    "        bmu_dict = dict(zip(unique.astype(int), counts))\n",
    "\n",
    "        for bmu, count in bmu_dict.items():\n",
    "            i = int(bmu / self.label_map.shape[1])\n",
    "            j = bmu % self.label_map.shape[1]\n",
    "            self.hit_map[i, j] = count\n",
    "            \n",
    "        #print(np.shape(self.hit_map))\n",
    "\n",
    "    def set_label_map(self, train_y):\n",
    "        # print(self.label_map)\n",
    "\n",
    "        unique, counts = np.unique(self.bmu_list, return_counts=True)\n",
    "        bmu_dict = dict(zip(unique.astype(int), counts))\n",
    "        print(bmu_dict)\n",
    "\n",
    "        for bmu, count in bmu_dict.items():\n",
    "            # print('bmu: {}, count: {}'.format(bmu, count))\n",
    "            # print(self.bmu_list[self.bmu_list == bmu])\n",
    "            idx = np.where(self.bmu_list == bmu)\n",
    "            unique_labels, label_counts = np.unique(train_y[idx], return_counts=True)\n",
    "\n",
    "            labels_dict = dict(zip(unique_labels.astype(int), label_counts))\n",
    "            # print(labels_dict)\n",
    "\n",
    "            import operator\n",
    "            # print(max(labels_dict.items(), key=operator.itemgetter(1))[0])\n",
    "\n",
    "            i = int(bmu / self.label_map.shape[1])\n",
    "            j = bmu % self.label_map.shape[1]\n",
    "\n",
    "            self.label_map[i, j] = max(labels_dict.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "    @classmethod\n",
    "    def get_distance(cls, x1, x2):\n",
    "        return np.sum((x1 - x2) ** 2)\n",
    "\n",
    "    @classmethod\n",
    "    def decay_radius(cls, init_radius, e, time_constant):\n",
    "        return init_radius * np.exp(-e / time_constant)\n",
    "\n",
    "    @classmethod\n",
    "    def decay_learning_rate(cls, init_lr, e, num_epochs):\n",
    "        return init_lr * np.exp(-e / num_epochs)\n",
    "\n",
    "    @classmethod\n",
    "    def draw_square(cls, x, y, dim, color):\n",
    "        rect = plt.Rectangle((x, y), dim, dim, fc=color)\n",
    "\n",
    "        return rect\n",
    "\n",
    "    def show_hitmap(self, show_hits=False):\n",
    "        print(\"show hit map\")\n",
    "        #fig, ax = plt.subplots()\n",
    "        plt.figure()\n",
    "        plt.imshow(self.hit_map, cmap='jet')\n",
    "        plt.title('Hit map')\n",
    "        plt.colorbar()        \n",
    "        if show_hits:\n",
    "            for i in range(self.net_dim[0]):\n",
    "                for j in range(self.net_dim[1]):\n",
    "                    c = self.hit_map[j,i]\n",
    "                    plt.text(i, j, str(c), va='center', ha='center')    \n",
    "        plt.show()\n",
    "        \n",
    "    def show_umatrix(self):\n",
    "        plt.figure()\n",
    "        plt.imshow(self.umatrix, cmap='jet')\n",
    "        plt.title('U-Matrix')\n",
    "        plt.colorbar()\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "\n",
    "    def set_umatrix(self, nbhd='neumann'):\n",
    "        for i in range(self.weights.shape[0]):\n",
    "            for j in range(self.weights.shape[1]):\n",
    "                self.umatrix[i, j] = self.calculate_average_distance([i, j], nbhd=nbhd)\n",
    "\n",
    "    def calculate_average_distance(self, index, nbhd='neumann'):\n",
    "        avg_distance = -1\n",
    "\n",
    "        if nbhd == 'neumann':\n",
    "            n = np.zeros([4])\n",
    "            div = 4\n",
    "            x = index[0]\n",
    "            y = index[1]\n",
    "            # Above\n",
    "            if (x - 1) >= 0:\n",
    "                n[0] = np.sqrt(SOM.get_distance(self.weights[x - 1, y, :], self.weights[x, y, :]))\n",
    "            else:\n",
    "                div -= 1\n",
    "            # Below\n",
    "            if (x + 1) < self.weights.shape[0]:\n",
    "                n[1] = np.sqrt(SOM.get_distance(self.weights[x + 1, y, :], self.weights[x, y, :]))\n",
    "            else:\n",
    "                div -= 1\n",
    "            # Left\n",
    "            if (y - 1) >= 0:\n",
    "                n[2] = np.sqrt(SOM.get_distance(self.weights[x, y - 1, :], self.weights[x, y, :]))\n",
    "            else:\n",
    "                div -= 1\n",
    "            # Right\n",
    "            if (y + 1) < self.weights.shape[1]:\n",
    "                n[3] = np.sqrt(SOM.get_distance(self.weights[x, y + 1, :], self.weights[x, y, :]))\n",
    "            else:\n",
    "                div -= 1\n",
    "\n",
    "            avg_distance = np.sum(n) / div\n",
    "        elif nbhd == 'moore':\n",
    "            # TODO implement for moore neighborhood\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            print('Not a valid Neighborhood')\n",
    "\n",
    "        return avg_distance\n",
    "\n",
    "    def set_umat_2(self):\n",
    "        # TODO: Need to optimize this code\n",
    "        r = 0\n",
    "        for i in range(self.net_dim[0]):\n",
    "            c = 0\n",
    "            for j in range(self.net_dim[1]):\n",
    "                if c+1 < self.umat_2.shape[1]:\n",
    "                    self.umat_2[r, c+1] = SOM.get_distance(self.weights[i, j, :], self.weights[i, j+1, :])\n",
    "\n",
    "                if r+1 < self.umat_2.shape[0]:\n",
    "                    self.umat_2[r+1, c] = SOM.get_distance(self.weights[i, j, :], self.weights[i+1, j, :])\n",
    "                c = c+2\n",
    "            r = r+2\n",
    "\n",
    "        temp = np.zeros([self.umat_2.shape[0], self.umat_2.shape[1], self.weights.shape[2]])\n",
    "        r = 0\n",
    "        for i in range(0, self.umat_2.shape[0], 2):\n",
    "            c = 0\n",
    "            for j in range(0, self.umat_2.shape[1],2):\n",
    "                temp[i, j] = self.weights[r, c, :]\n",
    "\n",
    "                c += 1\n",
    "            r += 1\n",
    "\n",
    "        for i in range(self.umat_2.shape[0]):\n",
    "            for j in range(self.umat_2.shape[1]):\n",
    "                if i % 2 != 0 and j % 2 != 0:\n",
    "                    self.umat_2[i, j] = (SOM.get_distance(temp[i-1, j-1, :], temp[i+1, j+1, :]) +\n",
    "                                         SOM.get_distance(temp[i-1, j+1, :], temp[i+1, j-1, :]))/2\n",
    "\n",
    "    def show_umatrx_2(self, size=2):\n",
    "        max_dist = np.max(self.umat_2)\n",
    "        print(max_dist)\n",
    "        cmap = matplotlib.pyplot.get_cmap('jet', lut=256)\n",
    "        plt.figure()\n",
    "        plt.imshow(self.umat_2, cmap='jet')\n",
    "        plt.title('U-Matrix')\n",
    "        plt.colorbar()\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "        \n",
    "    def print_save_weights(self,fileName):\n",
    "        \"\"\"\n",
    "        for i in range(self.weights.shape[0]):\n",
    "            print(self.weights[i,:]) \n",
    "        \"\"\"  \n",
    "        np.save(fileName,self.weights)\n",
    "        #print(\"load: \\n\", np.load('maximums.npy'))\n",
    "\n",
    "def standardize_data(X):\n",
    "    x_norm = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    return x_norm\n",
    "    from tempfile import TemporaryFile   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 44)\n"
     ]
    }
   ],
   "source": [
    "dataset_name='TrainSet_Processed.csv'\n",
    "data1=genfromtxt(dataset_name,delimiter=\",\")\n",
    "print(np.shape(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22543, 44)\n"
     ]
    }
   ],
   "source": [
    "dataset_tst='TestSet_Processed.csv'\n",
    "data2=genfromtxt(dataset_tst,delimiter=\",\")\n",
    "print(np.shape(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67343,)\n",
      "(67343, 41)\n",
      "(41214,)\n",
      "(41214, 41)\n",
      "(125973, 44)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "ii = np.where(data1[:,43] == 0)[0]\n",
    "train_x=(data1[ii, 0:41])\n",
    "\n",
    "print(np.shape(ii))\n",
    "print(np.shape(train_x))\n",
    "\n",
    "ii = np.where(data1[:,41] == 1)[0]\n",
    "train_x_attack=(data1[ii, 0:41])\n",
    "\n",
    "print(np.shape(ii))\n",
    "print(np.shape(train_x_attack))\n",
    "print(np.shape(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9710,)\n",
      "(9710, 41)\n",
      "(4657,)\n",
      "(4657, 41)\n",
      "(22543, 44)\n"
     ]
    }
   ],
   "source": [
    "ii = np.where(data2[:,43] == 0)[0]\n",
    "test_x=(data2[ii, 0:41])\n",
    "\n",
    "print(np.shape(ii))\n",
    "print(np.shape(test_x))\n",
    "\n",
    "ii = np.where(data2[:,41] == 1)[0]\n",
    "test_x_attack=(data2[ii, 0:41])\n",
    "\n",
    "print(np.shape(ii))\n",
    "print(np.shape(test_x_attack))\n",
    "print(np.shape(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch:0\n",
      "Processing epoch:1\n",
      "Processing epoch:2\n",
      "Processing epoch:3\n",
      "Processing epoch:4\n"
     ]
    }
   ],
   "source": [
    "som_dim=8\n",
    "som = SOM(som_dim, som_dim)\n",
    "som.fit_model(train_x, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight1.npy\n",
      "(8, 8, 41)\n"
     ]
    }
   ],
   "source": [
    "filename_for_weight='weight1'\n",
    "som.print_save_weights(filename_for_weight)\n",
    "filename_for_weight=filename_for_weight+'.npy'\n",
    "print(filename_for_weight)\n",
    "points=np.load(filename_for_weight)\n",
    "print(np.shape(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 41)\n"
     ]
    }
   ],
   "source": [
    "BMUList=[]\n",
    "for i in range(0,som_dim):\n",
    "    for j in range(0,som_dim):        \n",
    "        BMUList.append(points[i,j,:])\n",
    "        \n",
    "print(np.shape(BMUList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "no_clusters=3\n",
    "kmeans = KMeans(n_clusters=no_clusters, random_state=0).fit(BMUList)\n",
    "labels_of_BMUs=kmeans.labels_\n",
    "print(np.shape(labels_of_BMUs))\n",
    "print(labels_of_BMUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#for each data point store the cluster label\n",
    "data_cluster_list=np.zeros(np.shape(train_x)[0]);\n",
    "for i in range(0,np.shape(train_x)[0]):\n",
    "    bmu_index, bmu = som.find_bmu(train_x[i, :])    \n",
    "    data_cluster_list[i]=(labels_of_BMUs[((bmu_index[0])*som_dim) +bmu_index[1]]);\n",
    "print(data_cluster_list) \n",
    "print(type(data_cluster_list))\n",
    "\n",
    "#check this code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________\n",
      "(67331, 41)\n",
      "________________________\n",
      "(5, 41)\n",
      "________________________\n",
      "(7, 41)\n"
     ]
    }
   ],
   "source": [
    "#seperate train data for k clusters \n",
    "\n",
    "datasets=[];\n",
    "for i in range(0,no_clusters):    \n",
    "    searchval = i\n",
    "    ii = np.where(data_cluster_list == i)[0]\n",
    "    print('________________________')\n",
    "    #print(ii)\n",
    "    datasets.append(train_x[ii, :])\n",
    "    print(np.shape(datasets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(67331, 41)\n",
      "1\n",
      "(5, 41)\n",
      "2\n",
      "(7, 41)\n",
      "OneClassSVM(cache_size=200, coef0=0.0, degree=2, gamma=0.1, kernel='poly',\n",
      "      max_iter=-1, nu=0.1, random_state=None, shrinking=True, tol=0.001,\n",
      "      verbose=False)\n"
     ]
    }
   ],
   "source": [
    "OCC_list = list()\n",
    " \n",
    "#create one class SVM for each data cluster\n",
    "for i in range(no_clusters):\n",
    "    OCC_list.append(svm.OneClassSVM(nu=0.1, kernel='poly',degree=2, gamma=0.1))\n",
    "    #OCC_list.append(svm.OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=0.1))\n",
    "#OCC_list.append(svm.OneClassSVM(nu=0.1, kernel='poly',degree=2, gamma=0.1))\n",
    "#OCC_list.append(svm.OneClassSVM(nu=0.2, kernel='poly',degree=2, gamma=0.1))\n",
    "#OCC_list.append(svm.OneClassSVM(nu=0.2, kernel='poly',degree=2, gamma=0.1))\n",
    "for i in range(no_clusters):\n",
    "    print(i)\n",
    "    OCC_list[i].fit(datasets[i])\n",
    "    print(np.shape(datasets[i]))\n",
    "    \n",
    "print(OCC_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 9.99509971340748\n"
     ]
    }
   ],
   "source": [
    "#normal Data : train\n",
    "data_set=train_x\n",
    "dim=np.shape(data_set)\n",
    "error_count=0;\n",
    "for i in range(dim[0]):\n",
    "    bmu_index, bmu, sorted_list=som.find_bmu_list(data_set[i,:])\n",
    "    n=[data_cluster_list[i] for i in (sorted_list[0:10])]\n",
    "    classfier_list=np.unique(n)\n",
    "    #print(classfier_list)\n",
    "    flag=1\n",
    "    for classifier_id in (classfier_list):\n",
    "        #print(classifier_id)\n",
    "        y_pred_train = OCC_list[int(classifier_id)].predict(data_set[i,:].reshape(1, -1))\n",
    "        #print(y_pred_train)\n",
    "        n_error_train = y_pred_train[y_pred_train == 1].size\n",
    "        #print(n_error_train)\n",
    "        #print('correct')\n",
    "        if n_error_train!=0:\n",
    "            flag=0\n",
    "            #print('correct')\n",
    "    \n",
    "    if flag==1:\n",
    "        error_count=error_count+1\n",
    "        #print('error')\n",
    "    #print('---------------------')\n",
    "    \n",
    "print('error',(error_count*100/dim[0]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 5.901132852729146\n"
     ]
    }
   ],
   "source": [
    "# test with normal data in the test set\n",
    "data_set=test_x\n",
    "dim=np.shape(data_set)\n",
    "error_count=0;\n",
    "for i in range(dim[0]):\n",
    "    bmu_index, bmu, sorted_list=som.find_bmu_list(data_set[i,:])\n",
    "    n=[data_cluster_list[i] for i in (sorted_list[0:10])]\n",
    "    classfier_list=np.unique(n)\n",
    "    #print(classfier_list)\n",
    "    flag=1\n",
    "    for classifier_id in (classfier_list):\n",
    "        #print(classifier_id)\n",
    "        y_pred_train = OCC_list[int(classifier_id)].predict(data_set[i,:].reshape(1, -1))\n",
    "        #print(y_pred_train)\n",
    "        n_error_train = y_pred_train[y_pred_train == 1].size\n",
    "        #print(n_error_train)\n",
    "        #print('correct')\n",
    "        if n_error_train!=0:\n",
    "            flag=0\n",
    "            #print('correct')\n",
    "    \n",
    "    if flag==1:\n",
    "        error_count=error_count+1\n",
    "        #print('error')\n",
    "    #print('---------------------')\n",
    "\n",
    "error_count1=error_count\n",
    "print('error',(error_count*100/dim[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 3.2209576980888985\n"
     ]
    }
   ],
   "source": [
    "# test with attack data in the test set\n",
    "data_set=test_x_attack\n",
    "dim=np.shape(data_set)\n",
    "error_count=0;\n",
    "for i in range(dim[0]):\n",
    "    bmu_index, bmu, sorted_list=som.find_bmu_list(data_set[i,:])\n",
    "    n=[data_cluster_list[i] for i in (sorted_list[0:10])]\n",
    "    classfier_list=np.unique(n)\n",
    "    #print(classfier_list)\n",
    "    flag=1\n",
    "    for classifier_id in (classfier_list):\n",
    "        #print(classifier_id)\n",
    "        y_pred_train = OCC_list[int(classifier_id)].predict(data_set[i,:].reshape(1, -1))\n",
    "        #print(y_pred_train)\n",
    "        n_error_train = y_pred_train[y_pred_train == 1].size\n",
    "        #print(n_error_train)\n",
    "        if n_error_train!=0:\n",
    "            flag=0\n",
    "            #print('correct')\n",
    "    \n",
    "    if flag==0:\n",
    "        error_count=error_count+1\n",
    "        #print('error')\n",
    "    #print('---------------------')\n",
    "error_count2=error_count   \n",
    "print('error',(error_count*100/dim[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 4.8138981899354585\n"
     ]
    }
   ],
   "source": [
    "# test with attack data in the train set\n",
    "data_set=train_x_attack\n",
    "dim=np.shape(data_set)\n",
    "error_count=0;\n",
    "for i in range(dim[0]):\n",
    "    bmu_index, bmu, sorted_list=som.find_bmu_list(data_set[i,:])\n",
    "    n=[data_cluster_list[i] for i in (sorted_list[0:10])]\n",
    "    classfier_list=np.unique(n)\n",
    "    #print(classfier_list)\n",
    "    flag=1\n",
    "    for classifier_id in (classfier_list):\n",
    "        #print(classifier_id)\n",
    "        y_pred_train = OCC_list[int(classifier_id)].predict(data_set[i,:].reshape(1, -1))\n",
    "        #print(y_pred_train)\n",
    "        n_error_train = y_pred_train[y_pred_train == 1].size\n",
    "        #print(n_error_train)\n",
    "        if n_error_train!=0:\n",
    "            flag=0\n",
    "            #print('correct')\n",
    "    \n",
    "    if flag==0:\n",
    "        error_count=error_count+1\n",
    "        #print('error')\n",
    "    #print('---------------------')\n",
    "error_count3=error_count    \n",
    "print('error',(error_count*100/dim[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test error 4.87036937082816\n"
     ]
    }
   ],
   "source": [
    "print('total test error',((error_count1+error_count2+error_count3)*100/(np.shape(test_x)[0]+np.shape(test_x_attack)[0]+np.shape(train_x_attack)[0]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy:  95.12963062917184\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: ', 100-((error_count1+error_count2+error_count3)*100/(np.shape(test_x)[0]+np.shape(test_x_attack)[0]+np.shape(train_x_attack)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "4.868570194850759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "95.13142980514924"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
