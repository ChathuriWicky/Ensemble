{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import genfromtxt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class SOM(object):\n",
    "    def __init__(self, m, n):\n",
    "        self.net_dim = np.array([m, n])\n",
    "        self.weights = None\n",
    "        self.hit_map = np.zeros([self.net_dim[0], self.net_dim[1]])\n",
    "        self.init_radius = np.max(self.net_dim)/2\n",
    "        self.umatrix = np.zeros([self.net_dim[0], self.net_dim[1]])\n",
    "        self.umat_2 = np.zeros([self.net_dim[0]*2 - 1, self.net_dim[1]*2 - 1])\n",
    "        self.bmu_list = None\n",
    "        self.label_map = np.zeros([self.net_dim[0], self.net_dim[1]]) + -1\n",
    "        self.classif_log=None # matrix for storing data for each neu, #times it becomed BMU for each class\n",
    "        self.neu_class=np.zeros([m*n])# store class for each neuron \n",
    "        self.trainAccuracy=None\n",
    "        self.testAccuracy=None\n",
    "\n",
    "    def fit_model(self, train_x, train_y=None, init_lr=0.1, epochs=100):\n",
    "        # Initializing the weight matrix\n",
    "        self.weights = np.random.random((self.net_dim[0], self.net_dim[1], train_x.shape[1]))\n",
    "        self.bmu_list = np.zeros(train_x.shape[0])\n",
    "        time_constant = epochs/np.log(self.init_radius)\n",
    "        \n",
    "        if not (train_y is None):\n",
    "            #print(\"np.unique(train_y).shape[0]\",np.unique(train_y).shape[0])\n",
    "            self.classif_log=np.zeros([np.unique(train_y).shape[0] , self.net_dim[0]*self.net_dim[1]])\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print('Processing epoch:{}'.format(epoch))\n",
    "            \"\"\"decay the radius and the learning rate\"\"\"\n",
    "            if epoch != 0:\n",
    "                radius = SOM.decay_radius(self.init_radius,epoch, time_constant)\n",
    "                lr = SOM.decay_learning_rate(init_lr, epoch, epochs)\n",
    "\n",
    "            else:\n",
    "                radius = self.init_radius\n",
    "                lr = init_lr\n",
    "\n",
    "            #print(\"train_x.shape[0]\",train_x.shape[0])            \n",
    "            randlist=random.sample(range(train_x.shape[0]), train_x.shape[0])\n",
    "            for t in range(train_x.shape[0]):\n",
    "\n",
    "                # Picking a random pattern\n",
    "                r = randlist[t]                \n",
    "                # Finding the bmu for the random pattern\n",
    "                bmu_index, bmu = self.find_bmu(train_x[r, :])\n",
    "                #print(\"bmu_index : \",bmu_index) \n",
    "                self.bmu_list[r] = bmu_index[0]*self.weights.shape[1] + bmu_index[1]\n",
    "                #print(\"self.bmu_list[r] :: \",self.bmu_list[r])\n",
    "\n",
    "                # updating the weights\n",
    "                for i in range(self.net_dim[0]):\n",
    "                    for j in range(self.net_dim[1]):\n",
    "                        w = self.weights[i, j, :]\n",
    "                        w_bmu_dist = SOM.get_distance(w, bmu)\n",
    "\n",
    "                        h = self.get_gaussian_membership(w_bmu_dist, radius)\n",
    "                        delta_w = (lr * h * (train_x[r, :] - w))\n",
    "                        new_w = w + delta_w\n",
    "                        self.weights[i, j, :] = new_w                        \n",
    "                        if np.isnan(self.weights).any():\n",
    "                            print(' weights NaN at epoch {}'.format(epoch))\n",
    "\n",
    "                            return\n",
    "                        # print('\\n')\n",
    "            ##\n",
    "            if not (train_y is None) :       \n",
    "                for t in range(train_x.shape[0]):\n",
    "                    bmu_index, bmu = self.find_bmu(train_x[t, :])\n",
    "                    self.bmu_list[t] = bmu_index[0]*self.weights.shape[1] + bmu_index[1]\n",
    "                    #print(\"self.bmu_list[r]\",self.bmu_list[r])\n",
    "                    self.classif_log[int(train_y[t]),int(self.bmu_list[t])]=(self.classif_log[int(train_y[t]),int(self.bmu_list[t])])+1\n",
    "                print(\"Train Accuracy\",(sum(self.classif_log.max(axis=0))*100)/ (train_x.shape[0]) )\n",
    "                self.classif_log=np.zeros([np.unique(train_y).shape[0] , self.net_dim[0]*self.net_dim[1]])\n",
    "                self.trainAccuracy=(sum(self.classif_log.max(axis=0))*100)/ (train_x.shape[0])\n",
    " \n",
    "        if not (train_y is None) :       \n",
    "            for t in range(train_x.shape[0]):\n",
    "                bmu_index, bmu = self.find_bmu(train_x[t, :])\n",
    "                self.bmu_list[t] = bmu_index[0]*self.weights.shape[1] + bmu_index[1]\n",
    "                #print(\"self.bmu_list[r]\",self.bmu_list[r])\n",
    "                \"\"\"                    \n",
    "                print(\"bla\", bmu_index,bmu ,\" t\",t) # bla [0, 2] [-0.002496    0.00031421 -0.00322767] print(\"Train y val :\",int(train_y[t]))\n",
    "                print(\"self.bmu_list :\",int(self.bmu_list[t]))\n",
    "                \"\"\"\n",
    "                #print(\"int(train_y[t])\",int(train_y[t]) )\n",
    "                #print(\"int(self.bmu_list[t])\",int(self.bmu_list[t]))\n",
    "                self.classif_log[int(train_y[t]),int(self.bmu_list[t])]=(self.classif_log[int(train_y[t]),int(self.bmu_list[t])])+1\n",
    "                        \n",
    "            print(\"Check \\n\",self.classif_log)        \n",
    "            self.neu_class=self.classif_log.argmax(axis=0) \n",
    "            print(\"self.neu_class\",self.neu_class)\n",
    "            print(\"Train Accuracy\",(sum(self.classif_log.max(axis=0))*100)/ (train_x.shape[0]) )\n",
    "            self.trainAccuracy=(sum(self.classif_log.max(axis=0))*100)/ (train_x.shape[0])\n",
    "        self.set_umatrix()\n",
    "        self.set_hitmap()\n",
    "        #now test for accuracy\n",
    "        #if train_y is not None:\n",
    "            #self.set_label_map(train_y)#this needs checking cz it prints something \n",
    "        \n",
    "    def test_model(self, test_x, test_y=None):\n",
    "        \n",
    "        correct=0;\n",
    "        \n",
    "        for t in range(test_x.shape[0]):\n",
    "            bmu_index, bmu = self.find_bmu(test_x[t, :])\n",
    "            neu_no=bmu_index[0]*self.weights.shape[1] + bmu_index[1]\n",
    "            #print(\"neu_no : \",neu_no)\n",
    "            class_label=self.neu_class[neu_no]\n",
    "\n",
    "            if(class_label==test_y[t]):\n",
    "                correct=correct+1\n",
    "        print(\"Test Accuracy : \", (correct*100/test_x.shape[0]))\n",
    "        self.testAccuracy=(correct*100/test_x.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "    def find_bmu(self, x):\n",
    "        min_dist = float('inf')\n",
    "        bmu_index = [-1, -1]\n",
    "        bmu = self.weights[0, 0, :]\n",
    "        for i in range(self.net_dim[0]):\n",
    "            for j in range(self.net_dim[1]):\n",
    "                w = self.weights[i, j, :]\n",
    "                d = SOM.get_distance(x, w)\n",
    "                #print(\"d : \",d)\n",
    "                if d < min_dist:\n",
    "                    min_dist = d\n",
    "                    bmu_index = [i, j]\n",
    "                    bmu = w\n",
    "\n",
    "        return bmu_index, bmu\n",
    "    \n",
    "    def find_bmu_list(self, x):\n",
    "        min_dist = float('inf')\n",
    "        bmu_index = [-1, -1]\n",
    "        bmu = self.weights[0, 0, :]\n",
    "        dis_list=[]\n",
    "        for i in range(self.net_dim[0]):\n",
    "            for j in range(self.net_dim[1]):\n",
    "                w = self.weights[i, j, :]\n",
    "                d = SOM.get_distance(x, w)\n",
    "                dis_list.append(d)\n",
    "                #print(\"d : \",d)\n",
    "                if d < min_dist:\n",
    "                    min_dist = d\n",
    "                    bmu_index = [i, j]\n",
    "                    bmu = w\n",
    "        s = dis_list\n",
    "        sorted_list=sorted(range(len(s)), key=lambda k: s[k])\n",
    "        #print(dis_list)\n",
    "        #print(bmu_index)\n",
    "        #print(dis_list[sorted_list[0]])\n",
    "        #print(min_dist)\n",
    "        return bmu_index, bmu, sorted_list\n",
    "\n",
    "    def get_gaussian_membership(self, squared_distance_from_bmu, radius):\n",
    "        h = np.exp(-squared_distance_from_bmu/(2*(radius**2)))\n",
    "        # h = np.exp(squared_distance_from_bmu/(2*(radius**2)))\n",
    "        # print('h:{}'.format(h))\n",
    "        return h\n",
    "\n",
    "    def set_hitmap(self):\n",
    "        unique, counts = np.unique(self.bmu_list, return_counts=True)\n",
    "        #print(\"unique\",unique)\n",
    "        #print(\"counts\",counts)\n",
    "        bmu_dict = dict(zip(unique.astype(int), counts))\n",
    "\n",
    "        for bmu, count in bmu_dict.items():\n",
    "            i = int(bmu / self.label_map.shape[1])\n",
    "            j = bmu % self.label_map.shape[1]\n",
    "            self.hit_map[i, j] = count\n",
    "            \n",
    "        #print(np.shape(self.hit_map))\n",
    "\n",
    "    def set_label_map(self, train_y):\n",
    "        # print(self.label_map)\n",
    "\n",
    "        unique, counts = np.unique(self.bmu_list, return_counts=True)\n",
    "        bmu_dict = dict(zip(unique.astype(int), counts))\n",
    "        print(bmu_dict)\n",
    "\n",
    "        for bmu, count in bmu_dict.items():\n",
    "            # print('bmu: {}, count: {}'.format(bmu, count))\n",
    "            # print(self.bmu_list[self.bmu_list == bmu])\n",
    "            idx = np.where(self.bmu_list == bmu)\n",
    "            unique_labels, label_counts = np.unique(train_y[idx], return_counts=True)\n",
    "\n",
    "            labels_dict = dict(zip(unique_labels.astype(int), label_counts))\n",
    "            # print(labels_dict)\n",
    "\n",
    "            import operator\n",
    "            # print(max(labels_dict.items(), key=operator.itemgetter(1))[0])\n",
    "\n",
    "            i = int(bmu / self.label_map.shape[1])\n",
    "            j = bmu % self.label_map.shape[1]\n",
    "\n",
    "            self.label_map[i, j] = max(labels_dict.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "    @classmethod\n",
    "    def get_distance(cls, x1, x2):\n",
    "        return np.sum((x1 - x2) ** 2)\n",
    "\n",
    "    @classmethod\n",
    "    def decay_radius(cls, init_radius, e, time_constant):\n",
    "        return init_radius * np.exp(-e / time_constant)\n",
    "\n",
    "    @classmethod\n",
    "    def decay_learning_rate(cls, init_lr, e, num_epochs):\n",
    "        return init_lr * np.exp(-e / num_epochs)\n",
    "\n",
    "    @classmethod\n",
    "    def draw_square(cls, x, y, dim, color):\n",
    "        rect = plt.Rectangle((x, y), dim, dim, fc=color)\n",
    "\n",
    "        return rect\n",
    "\n",
    "    def show_hitmap(self, show_hits=False):\n",
    "        print(\"show hit map\")\n",
    "        #fig, ax = plt.subplots()\n",
    "        plt.figure()\n",
    "        plt.imshow(self.hit_map, cmap='jet')\n",
    "        plt.title('Hit map')\n",
    "        plt.colorbar()        \n",
    "        if show_hits:\n",
    "            for i in range(self.net_dim[0]):\n",
    "                for j in range(self.net_dim[1]):\n",
    "                    c = self.hit_map[j,i]\n",
    "                    plt.text(i, j, str(c), va='center', ha='center')    \n",
    "        plt.show()\n",
    "        \n",
    "    def show_umatrix(self):\n",
    "        plt.figure()\n",
    "        plt.imshow(self.umatrix, cmap='jet')\n",
    "        plt.title('U-Matrix')\n",
    "        plt.colorbar()\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "\n",
    "    def set_umatrix(self, nbhd='neumann'):\n",
    "        for i in range(self.weights.shape[0]):\n",
    "            for j in range(self.weights.shape[1]):\n",
    "                self.umatrix[i, j] = self.calculate_average_distance([i, j], nbhd=nbhd)\n",
    "\n",
    "    def calculate_average_distance(self, index, nbhd='neumann'):\n",
    "        avg_distance = -1\n",
    "\n",
    "        if nbhd == 'neumann':\n",
    "            n = np.zeros([4])\n",
    "            div = 4\n",
    "            x = index[0]\n",
    "            y = index[1]\n",
    "            # Above\n",
    "            if (x - 1) >= 0:\n",
    "                n[0] = np.sqrt(SOM.get_distance(self.weights[x - 1, y, :], self.weights[x, y, :]))\n",
    "            else:\n",
    "                div -= 1\n",
    "            # Below\n",
    "            if (x + 1) < self.weights.shape[0]:\n",
    "                n[1] = np.sqrt(SOM.get_distance(self.weights[x + 1, y, :], self.weights[x, y, :]))\n",
    "            else:\n",
    "                div -= 1\n",
    "            # Left\n",
    "            if (y - 1) >= 0:\n",
    "                n[2] = np.sqrt(SOM.get_distance(self.weights[x, y - 1, :], self.weights[x, y, :]))\n",
    "            else:\n",
    "                div -= 1\n",
    "            # Right\n",
    "            if (y + 1) < self.weights.shape[1]:\n",
    "                n[3] = np.sqrt(SOM.get_distance(self.weights[x, y + 1, :], self.weights[x, y, :]))\n",
    "            else:\n",
    "                div -= 1\n",
    "\n",
    "            avg_distance = np.sum(n) / div\n",
    "        elif nbhd == 'moore':\n",
    "            # TODO implement for moore neighborhood\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            print('Not a valid Neighborhood')\n",
    "\n",
    "        return avg_distance\n",
    "\n",
    "    def set_umat_2(self):\n",
    "        # TODO: Need to optimize this code\n",
    "        r = 0\n",
    "        for i in range(self.net_dim[0]):\n",
    "            c = 0\n",
    "            for j in range(self.net_dim[1]):\n",
    "                if c+1 < self.umat_2.shape[1]:\n",
    "                    self.umat_2[r, c+1] = SOM.get_distance(self.weights[i, j, :], self.weights[i, j+1, :])\n",
    "\n",
    "                if r+1 < self.umat_2.shape[0]:\n",
    "                    self.umat_2[r+1, c] = SOM.get_distance(self.weights[i, j, :], self.weights[i+1, j, :])\n",
    "                c = c+2\n",
    "            r = r+2\n",
    "\n",
    "        temp = np.zeros([self.umat_2.shape[0], self.umat_2.shape[1], self.weights.shape[2]])\n",
    "        r = 0\n",
    "        for i in range(0, self.umat_2.shape[0], 2):\n",
    "            c = 0\n",
    "            for j in range(0, self.umat_2.shape[1],2):\n",
    "                temp[i, j] = self.weights[r, c, :]\n",
    "\n",
    "                c += 1\n",
    "            r += 1\n",
    "\n",
    "        for i in range(self.umat_2.shape[0]):\n",
    "            for j in range(self.umat_2.shape[1]):\n",
    "                if i % 2 != 0 and j % 2 != 0:\n",
    "                    self.umat_2[i, j] = (SOM.get_distance(temp[i-1, j-1, :], temp[i+1, j+1, :]) +\n",
    "                                         SOM.get_distance(temp[i-1, j+1, :], temp[i+1, j-1, :]))/2\n",
    "\n",
    "    def show_umatrx_2(self, size=2):\n",
    "        max_dist = np.max(self.umat_2)\n",
    "        print(max_dist)\n",
    "        cmap = matplotlib.pyplot.get_cmap('jet', lut=256)\n",
    "        plt.figure()\n",
    "        plt.imshow(self.umat_2, cmap='jet')\n",
    "        plt.title('U-Matrix')\n",
    "        plt.colorbar()\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "        \n",
    "    def print_save_weights(self,fileName):\n",
    "        \"\"\"\n",
    "        for i in range(self.weights.shape[0]):\n",
    "            print(self.weights[i,:]) \n",
    "        \"\"\"  \n",
    "        np.save(fileName,self.weights)\n",
    "        #print(\"load: \\n\", np.load('maximums.npy'))\n",
    "\n",
    "def standardize_data(X):\n",
    "    x_norm = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    return x_norm\n",
    "    from tempfile import TemporaryFile   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_name='KDDTrainset.csv'\n",
    "data1=genfromtxt(dataset_name,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67343,)\n",
      "(67343, 41)\n",
      "(58630,)\n",
      "(58630, 44)\n",
      "(125973, 44)\n"
     ]
    }
   ],
   "source": [
    "ii = np.where(data1[:,43] == 1)[0]\n",
    "normal_data=(data1[ii, 0:41])\n",
    "\n",
    "print(np.shape(ii))\n",
    "print(np.shape(normal_data))\n",
    "\n",
    "ii = np.where(data1[:,43] != 1)[0]\n",
    "attack_data=(data1[ii, :])\n",
    "\n",
    "print(np.shape(ii))\n",
    "print(np.shape(attack_data))\n",
    "\n",
    "print(np.shape(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 41)\n",
      "(10000, 41)\n",
      "(20000, 41)\n"
     ]
    }
   ],
   "source": [
    "train_x=normal_data[0:50000,0:41]\n",
    "print(np.shape(train_x))\n",
    "normal_test=normal_data[50001:60001,0:41]\n",
    "print(np.shape(normal_test))\n",
    "attack_test=attack_data[0:20000,0:41]\n",
    "print(np.shape(attack_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch:0\n",
      "Processing epoch:1\n",
      "Processing epoch:2\n",
      "Processing epoch:3\n",
      "Processing epoch:4\n"
     ]
    }
   ],
   "source": [
    "som = SOM(8, 8)\n",
    "som.fit_model(train_x, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 41)\n"
     ]
    }
   ],
   "source": [
    "filename_for_weight='weight1'\n",
    "som.print_save_weights(filename_for_weight)\n",
    "points=np.load('bla.npy')\n",
    "print(np.shape(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 41)\n"
     ]
    }
   ],
   "source": [
    "BMUList=[]\n",
    "for i in range(0,8):\n",
    "    for j in range(0,8):        \n",
    "        BMUList.append(points[i,j,:])\n",
    "        \n",
    "print(np.shape(BMUList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "[0 0 4 0 0 0 0 5 0 0 7 0 6 0 0 0 3 0 8 9 0 0 0 9 0 0 0 0 1 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "no_clusters=10\n",
    "kmeans = KMeans(n_clusters=no_clusters, random_state=0).fit(BMUList)\n",
    "labels_of_BMUs=kmeans.labels_\n",
    "print(np.shape(labels_of_BMUs))\n",
    "print(labels_of_BMUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  0.  0. ...,  9.  0.  0.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#for each data point store the cluster label\n",
    "data_cluster_list=np.zeros(20000);\n",
    "for i in range(0,20000):\n",
    "    bmu_index, bmu = som.find_bmu(train_x[i, :])    \n",
    "    data_cluster_list[i]=(labels_of_BMUs[((bmu_index[0])*8) +bmu_index[1]]);\n",
    "print(data_cluster_list) \n",
    "print(type(data_cluster_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________\n",
      "[    1     2     3 ..., 19996 19998 19999]\n",
      "________________________\n",
      "[  213   551  1056  3156  3847  5050  6226  7944  8702  9634 10128 10669\n",
      " 10938 11014 12285 12786 13053 13553 13654 16042 17455 19012]\n",
      "________________________\n",
      "[  120   309   417   496   725   753  1086  1136  1204  1223  1753  1873\n",
      "  1884  1952  1985  2105  2181  2487  2496  2640  2772  2907  3041  3085\n",
      "  3108  3239  3348  3483  3515  3845  3856  3916  4144  4287  4388  5004\n",
      "  5021  5068  5340  6380  6479  6978  7066  7435  7631  7643  7748  7876\n",
      "  8005  8019  8091  8110  8179  8243  8409  8476  8659  8929  8947  9003\n",
      "  9029  9066  9423  9427  9791 10247 10275 10411 10664 11351 11530 11839\n",
      " 12478 12492 12555 12618 12738 12936 13311 13339 13420 13427 13558 13785\n",
      " 13867 14250 14426 14721 14857 15175 15315 15367 15482 15518 15650 15684\n",
      " 15726 15942 16030 16075 16181 16504 16711 16993 17082 17138 17172 17179\n",
      " 17203 17359 17605 17785 17816 18190 18192 18239 18553 18566 18606 18616\n",
      " 18759 19114 19193 19294 19627]\n",
      "________________________\n",
      "[    0    28    82   160   230   374   491   546   622   709   966  1065\n",
      "  1093  1236  1266  1275  1331  1390  1405  1416  1646  1666  1677  1786\n",
      "  1914  1964  1995  2006  2285  2350  2353  2395  2410  2455  2498  2582\n",
      "  2688  2705  2712  2785  2893  3006  3098  3118  3293  3357  3365  3466\n",
      "  3490  3512  3615  3844  3956  4006  4118  4539  4543  4565  4585  4608\n",
      "  4679  4738  4802  4810  4819  4835  4887  5000  5216  5238  5239  5408\n",
      "  5627  5667  5669  5682  5753  5941  5960  5979  6006  6008  6009  6043\n",
      "  6175  6186  6427  6464  6532  6638  6674  6721  6734  6760  6907  6914\n",
      "  6993  7195  7272  7320  7491  7514  7593  7599  7782  8015  8058  8097\n",
      "  8386  8393  8403  8511  8522  8530  8581  8744  8776  8807  8891  8913\n",
      "  9100  9132  9157  9336  9404  9409  9412  9471  9556  9668  9685  9705\n",
      "  9722  9764  9812  9832  9844  9846  9867  9911 10033 10160 10161 10309\n",
      " 10450 10470 10594 10736 10758 10865 10923 10940 10994 11018 11028 11043\n",
      " 11067 11098 11110 11173 11243 11360 11385 11416 11465 11487 11541 11684\n",
      " 11808 11837 12006 12122 12131 12505 12616 12637 12665 12666 12720 12744\n",
      " 12789 12863 12880 12881 12902 12925 13018 13221 13280 13444 13461 13483\n",
      " 13549 13581 13701 13827 13857 13863 13914 13926 14131 14141 14327 14358\n",
      " 14472 14586 14646 14706 14742 14744 14835 14847 14955 14993 15221 15222\n",
      " 15234 15237 15395 15614 15819 15983 15985 16054 16129 16215 16343 16488\n",
      " 16496 16499 16544 16572 16745 16830 16849 16863 16899 16927 16945 17013\n",
      " 17022 17073 17228 17474 17487 17637 17729 17736 17738 17782 17783 17853\n",
      " 18070 18119 18137 18217 18292 18340 18382 18412 18584 18625 18721 18732\n",
      " 18744 18753 18783 18816 18838 18906 18946 19258 19404 19534 19688 19741\n",
      " 19986]\n",
      "________________________\n",
      "[   44   122   397   445   482   492   544   555   608   730   986  1019\n",
      "  1097  1254  1296  1324  1439  1525  1599  1810  1889  1913  1992  2023\n",
      "  2073  2085  2158  2295  2308  2358  2620  2638  2757  2784  2889  2939\n",
      "  2988  3018  3267  3415  3465  3552  3554  3563  3567  3600  3655  3693\n",
      "  3855  3972  3983  4054  4165  4211  4214  4258  4278  4420  4522  4714\n",
      "  4749  4775  4877  4927  4993  5081  5123  5158  5178  5329  5456  5485\n",
      "  5513  5638  5713  5740  5793  5848  5867  5872  6117  6136  6208  6306\n",
      "  6426  6455  6486  6525  6554  6561  6710  6765  6821  6856  6886  6951\n",
      "  7027  7031  7048  7067  7091  7219  7224  7373  7496  7510  7701  7761\n",
      "  7781  7914  7950  7985  8083  8134  8366  8435  8452  8508  8928  8972\n",
      "  9034  9120  9161  9322  9493  9563  9564  9618  9734  9739  9804  9866\n",
      " 10086 10172 10198 10219 10366 10441 10474 10546 10567 10603 10604 10846\n",
      " 10905 10928 11024 11089 11462 11520 11747 11770 11778 11813 11874 11908\n",
      " 11988 12099 12205 12329 12446 12475 12513 12515 12582 12735 12776 12946\n",
      " 13234 13302 13308 13320 13321 13447 13589 13761 13800 14007 14094 14105\n",
      " 14160 14311 14370 14498 14550 14660 14663 14770 14817 14849 14982 15153\n",
      " 15173 15248 15290 15303 15510 15539 15547 15608 15659 15688 15782 15853\n",
      " 15886 16077 16166 16313 16638 16663 16812 16886 16909 16917 16930 17143\n",
      " 17315 17505 17587 17635 17717 17727 17792 17798 17886 17954 18022 18187\n",
      " 18229 18318 18377 18413 18439 18570 18795 18797 18879 18931 19024 19030\n",
      " 19067 19083 19310 19341 19400 19413 19414 19455 19468 19524 19542 19668\n",
      " 19674 19710 19887 19935]\n",
      "________________________\n",
      "[   26    40   257   388   550   918  1360  1545  1610  1972  2078  2390\n",
      "  2404  2604  3027  3131  3174  3447  3468  3473  3730  3802  4156  4753\n",
      "  5048  5064  5103  5484  5508  5952  6334  7034  7344  7390  7398  7421\n",
      "  7697  7831  8012  8022  8223  8258  8288  8651  8896  9262 10329 10333\n",
      " 10347 11085 11176 11756 11877 11881 12273 12511 13230 13436 13441 13626\n",
      " 13689 13722 13759 13868 14049 15117 15155 15788 16369 16666 16973 17133\n",
      " 17454 17758 17762 17891 17971 18057 18764 19265 19493 19663]\n",
      "________________________\n",
      "[   47   255   330   338   934  1043  1209  1303  1510  1652  1830  1832\n",
      "  1836  2156  2177  2218  2273  2467  2485  2859  2876  3940  3988  4064\n",
      "  4194  4425  4686  4742  5314  5348  5416  5668  5675  5706  6910  7158\n",
      "  7448  7692  7934  8678  8878  9042  9222  9421  9520 10254 10622 10731\n",
      " 10893 11132 11405 12095 12321 12462 13007 13089 13178 13468 13563 13613\n",
      " 13848 13880 14244 14375 15573 15722 15846 15852 15899 15915 15956 16326\n",
      " 16351 16623 16942 16998 17430 17446 17828 18206 18261 19077 19085 19141\n",
      " 19347 19442 19490 19662 19800 19840]\n",
      "________________________\n",
      "[   84   162   313   394   414   453   507   532   574   605   629   694\n",
      "   771   795   854   904  1160  1348  1349  1362  1511  1620  1692  1769\n",
      "  1846  1949  2305  2338  2506  2516  2662  2725  2806  3060  3088  3154\n",
      "  3229  3279  3508  3571  3788  3891  3931  4202  4260  4324  4373  4446\n",
      "  4613  4655  4680  4702  4988  5002  5135  5144  5188  5194  5418  5529\n",
      "  5546  5594  5678  5756  6007  6341  6481  6599  6632  6714  6787  6791\n",
      "  6817  6868  6878  6902  6979  7054  7145  7240  7353  7380  7447  7581\n",
      "  7835  7990  8073  8099  8127  8167  8354  8374  8385  8447  8537  8616\n",
      "  8618  8782  8794  8872  8949  8991  9004  9091  9288  9317  9399  9438\n",
      "  9446  9654  9696  9984 10019 10030 10104 10362 10393 10434 10448 10457\n",
      " 10651 10670 10732 11147 11229 11314 11390 11521 11611 11661 11704 11741\n",
      " 11880 11947 12008 12011 12014 12036 12123 12126 12187 12214 12359 12363\n",
      " 12407 12450 12585 12629 12682 12701 12945 13110 13271 13324 13338 13358\n",
      " 13473 13594 13809 13988 14148 14188 14201 14237 14301 14307 14343 14514\n",
      " 14836 14886 14893 14999 15137 15289 15437 15494 15790 15905 16189 16226\n",
      " 16553 16653 16687 16727 16733 16819 16901 17054 17127 17184 17200 17250\n",
      " 17333 17498 17509 17585 17607 17701 17706 18276 18359 18374 18447 18628\n",
      " 18670 18681 18735 18746 18763 18811 18836 18980 18998 19033 19040 19338\n",
      " 19357 19399 19447 19512 19533 19650 19682 19843 19868 19891 19941]\n",
      "________________________\n",
      "[   33   296   364   592   728  1151  1178  1193  1564  2296  2481  2734\n",
      "  3287  3318  3886  4296  4323  4493  4555  5014  5108  5195  5301  5573\n",
      "  6643  6869  7045  7070  7157  7811  7923  8241  8544  8712  8783  9046\n",
      "  9388  9679  9699  9872 10090 10445 10478 10770 10808 10947 10966 11212\n",
      " 11435 11451 11554 11559 11700 11743 12140 12364 12547 12873 12977 13000\n",
      " 13016 13192 13263 13267 14081 14161 14181 14267 14393 14561 14767 15204\n",
      " 15589 15628 15767 15825 15882 16154 16165 16314 16349 16905 16966 17095\n",
      " 17348 17463 17600 17832 17933 18250 18277 18298 18435 18695 19206 19218\n",
      " 19852 19878 19948 19959]\n",
      "________________________\n",
      "[   68    97   150   168   189   200   225   271   325   356   357   380\n",
      "   399   409   416   419   450   462   463   474   520   563   565   573\n",
      "   591   612   631   638   666   688   720   752   791   810   818   865\n",
      "   882   907   927   954   975  1014  1015  1038  1042  1045  1054  1091\n",
      "  1104  1127  1132  1137  1142  1154  1177  1186  1187  1195  1239  1251\n",
      "  1315  1370  1408  1425  1444  1469  1506  1523  1556  1560  1568  1579\n",
      "  1581  1623  1627  1663  1693  1700  1721  1725  1736  1777  1796  1815\n",
      "  1824  1848  1854  1885  1902  1907  1917  1936  1958  2001  2007  2046\n",
      "  2065  2090  2103  2132  2153  2198  2204  2249  2250  2281  2297  2359\n",
      "  2377  2429  2562  2660  2664  2691  2704  2816  2848  2860  2895  3000\n",
      "  3015  3076  3083  3092  3107  3113  3138  3180  3190  3210  3217  3221\n",
      "  3244  3274  3280  3319  3346  3360  3387  3400  3401  3411  3431  3462\n",
      "  3474  3500  3540  3565  3566  3609  3618  3653  3668  3676  3678  3687\n",
      "  3775  3800  3846  3850  3864  3935  3942  3948  3968  4007  4023  4049\n",
      "  4057  4058  4073  4085  4091  4280  4290  4347  4348  4363  4422  4423\n",
      "  4460  4461  4506  4512  4530  4629  4632  4669  4678  4709  4716  4751\n",
      "  4756  4788  4806  4894  4899  4954  4965  5022  5046  5101  5102  5104\n",
      "  5125  5153  5169  5231  5240  5283  5299  5324  5331  5358  5395  5480\n",
      "  5481  5532  5541  5590  5604  5610  5633  5660  5686  5722  5731  5765\n",
      "  5771  5787  5789  5819  5834  5841  5878  5893  5946  5948  5983  6004\n",
      "  6026  6028  6069  6070  6079  6119  6133  6138  6145  6173  6205  6279\n",
      "  6292  6304  6352  6407  6410  6431  6494  6612  6639  6654  6656  6685\n",
      "  6744  6768  6797  6819  6866  6876  6891  6935  6945  6959  6975  6977\n",
      "  7001  7018  7064  7069  7083  7092  7117  7190  7253  7271  7280  7310\n",
      "  7331  7445  7462  7518  7529  7556  7576  7595  7641  7646  7648  7695\n",
      "  7699  7703  7704  7712  7715  7720  7746  7759  7819  7854  7884  7891\n",
      "  7910  7932  7942  7948  7975  8049  8055  8092  8101  8121  8130  8141\n",
      "  8146  8158  8176  8240  8270  8286  8318  8326  8368  8389  8419  8466\n",
      "  8467  8471  8528  8610  8626  8635  8681  8695  8703  8707  8719  8728\n",
      "  8789  8821  8826  8837  8838  8846  8850  8868  8876  8927  8932  8946\n",
      "  8966  9019  9048  9079  9140  9143  9169  9196  9218  9220  9244  9284\n",
      "  9306  9316  9320  9324  9334  9341  9381  9418  9431  9458  9470  9488\n",
      "  9518  9525  9549  9627  9650  9656  9658  9680  9686  9694  9697  9707\n",
      "  9709  9713  9715  9821  9826  9830  9880  9886  9979 10014 10043 10047\n",
      " 10141 10181 10189 10216 10246 10267 10326 10330 10349 10369 10384 10420\n",
      " 10476 10498 10507 10521 10538 10563 10573 10598 10631 10632 10663 10717\n",
      " 10740 10786 10830 10838 10850 10888 10897 10916 10945 10953 10955 10971\n",
      " 10973 10974 10983 11075 11094 11191 11265 11267 11279 11282 11310 11363\n",
      " 11383 11470 11473 11490 11491 11509 11529 11564 11567 11574 11578 11599\n",
      " 11644 11666 11677 11678 11699 11715 11761 11783 11798 11799 11817 11841\n",
      " 11845 11857 11904 11998 12009 12013 12026 12120 12121 12138 12178 12188\n",
      " 12246 12349 12355 12378 12429 12502 12541 12553 12578 12584 12653 12681\n",
      " 12700 12703 12708 12710 12725 12758 12811 12813 12838 12844 12857 12871\n",
      " 12890 12978 13001 13005 13038 13041 13077 13081 13093 13097 13104 13223\n",
      " 13241 13243 13268 13314 13327 13329 13343 13379 13382 13452 13457 13464\n",
      " 13495 13497 13546 13571 13572 13575 13590 13593 13610 13637 13694 13716\n",
      " 13718 13746 13786 13801 13822 13829 13836 13837 13843 13847 13858 13870\n",
      " 13899 13913 13942 14013 14030 14039 14098 14138 14140 14166 14178 14182\n",
      " 14211 14217 14259 14263 14283 14289 14298 14302 14323 14332 14339 14347\n",
      " 14356 14488 14521 14542 14576 14611 14620 14630 14652 14799 14813 14842\n",
      " 14883 14889 14892 14957 14964 14974 14977 14978 14988 15037 15154 15176\n",
      " 15213 15216 15263 15341 15372 15387 15412 15421 15422 15429 15448 15530\n",
      " 15536 15581 15593 15599 15609 15634 15649 15674 15695 15704 15743 15810\n",
      " 15815 15843 15861 15869 15881 15883 15891 15918 15931 15943 15948 16002\n",
      " 16010 16027 16087 16097 16106 16130 16151 16172 16179 16230 16246 16280\n",
      " 16292 16321 16401 16472 16497 16532 16542 16545 16547 16548 16549 16618\n",
      " 16652 16695 16726 16760 16783 16800 16806 16811 16926 16958 16972 16996\n",
      " 17006 17028 17048 17087 17103 17159 17189 17202 17210 17245 17249 17261\n",
      " 17303 17324 17342 17398 17414 17421 17451 17468 17481 17513 17521 17553\n",
      " 17558 17562 17569 17598 17627 17666 17677 17696 17753 17763 17769 17811\n",
      " 17863 17866 17903 17909 17910 17926 17969 18018 18020 18039 18071 18078\n",
      " 18108 18140 18159 18196 18215 18223 18273 18303 18322 18326 18354 18386\n",
      " 18402 18421 18438 18473 18486 18517 18536 18541 18544 18547 18579 18622\n",
      " 18635 18659 18667 18677 18716 18751 18786 18818 18851 18865 18875 18939\n",
      " 18956 18957 18959 19074 19075 19107 19170 19176 19185 19216 19230 19292\n",
      " 19302 19325 19394 19410 19430 19431 19496 19528 19546 19578 19584 19597\n",
      " 19619 19659 19673 19675 19694 19695 19707 19715 19898 19962 19963 19980\n",
      " 19997]\n"
     ]
    }
   ],
   "source": [
    "#seperate train data for k clusters \n",
    "\n",
    "datasets=[];\n",
    "for i in range(0,no_clusters):    \n",
    "    searchval = i\n",
    "    ii = np.where(data_cluster_list == i)[0]\n",
    "    print('________________________')\n",
    "    print(ii)\n",
    "    datasets.append(train_x[ii, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(22, 41)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(datasets))\n",
    "print(np.shape(datasets[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
      "      max_iter=-1, nu=0.03, random_state=None, shrinking=True, tol=0.001,\n",
      "      verbose=False)\n"
     ]
    }
   ],
   "source": [
    "OCC_list = list()\n",
    "\n",
    "#create one class SVM for each data cluster\n",
    "for i in range(no_clusters):\n",
    "    OCC_list.append(svm.OneClassSVM(nu=0.03, kernel=\"rbf\", gamma=0.1))\n",
    "    \n",
    "for i in range(no_clusters):\n",
    "    OCC_list[i].fit(datasets[i])\n",
    "    \n",
    "print(OCC_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 41)\n",
      "[3, 3]\n",
      "[27, 26, 58, 30, 0, 49, 44, 11, 38, 5, 1, 34, 46, 13, 8, 43, 23, 42, 60, 59, 7, 17, 15, 50, 36, 12, 57, 18, 37, 6, 14, 10, 39, 52, 19, 33, 62, 16, 51, 2, 63, 55, 56, 32, 29, 53, 3, 45, 20, 47, 54, 4, 9, 24, 61, 25, 21, 28, 35, 31, 22, 40, 48, 41]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(normal_test))\n",
    "bmu_index, bmu, sorted_list=som.find_bmu_list(train_x[2,:])\n",
    "print(bmu_index)\n",
    "print(sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 26, 58, 30, 0, 49, 44, 11, 38, 5]\n",
      "[0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0]\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.  3.  4.  5.]\n"
     ]
    }
   ],
   "source": [
    "#find possible clusters a point can belongs to\n",
    "print(sorted_list[0:10])\n",
    "n=[data_cluster_list[i] for i in (sorted_list[0:10])]\n",
    "print(n)\n",
    "print(type(data_cluster_list))\n",
    "print(np.unique(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = OCC_list[0].predict(train_x[2,:].reshape(1, -1))\n",
    "\n",
    "n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "print(n_error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-18-dc385c540dbe>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-dc385c540dbe>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26103\n",
      "52.206\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "OCSVM_classifier=svm.OneClassSVM(nu=0.03, kernel=\"rbf\", gamma=0.1)\n",
    "OCSVM_classifier.fit(train_x)\n",
    "y_pred_train = OCSVM_classifier.predict(train_x)\n",
    "\n",
    "n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "print(n_error_train)\n",
    "print(n_error_train*100/np.shape(train_x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 41)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
